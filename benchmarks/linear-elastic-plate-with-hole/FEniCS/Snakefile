from pathlib import Path

files = list(Path(".").glob("parameters_*.json"))

# extract the configuration from the parameter files
# by reading in the json files and extracting the "configuration" value
# configuration stores the appendix in the output files)"
# in theory, you could make that identical so parameters_1.json with configuration "1" 
# would produce summary_1.json
import json
def get_configuration(file):
    with open(file, 'r') as f:
        data = json.load(f)
    # Check if "configuration" key exists, otherwise use the file name
    if "configuration" in data:
        return data["configuration"]
    # Fallback to using the file name if "configuration" is not present
    # Assuming the file name is in the format "parameters_<configuration>.json"
    if file.stem.startswith("parameters_"):
        return file.stem.split("_")[1]
    # If no configuration is found, raise an error
    raise ValueError(f"Configuration key not found for file: {file}")

# Create a dictionary of configurations (key is the name of the parameter file)
# configurations: {Path("parameters_1.json"): "1", ...}
configurations = {file: get_configuration(file) for file in files if file.is_file()}
# Reverse mapping for easy lookup by configuration name
configuration_to_parameter_file = {v: str(k) for k, v in configurations.items()}

tools = ["fenics"]

rule all:
    input:
        expand("data/summary_{tool}.json", tool=tools),
        expand("data/summary_{tool}.h5", tool=tools),

rule create_mesh:    
    input:
        script = "create_mesh.py",
        parameters = lambda wildcards: configuration_to_parameter_file[wildcards.configuration],
    output:
        mesh = "data/mesh_{configuration}.msh",
    conda: "environment_mesh.yml"
    shell:
        """
        python3 {input.script} --input_parameter_file {input.parameters} --output_mesh_file {output.mesh}
        """

rule run_simulation:
    input: 
        script = "run_simulation_{tool}.py",
        parameters = lambda wildcards: configuration_to_parameter_file[wildcards.configuration],
        mesh = "data/mesh_{configuration}.msh",
    output:
        hdf5 = "data/solution_field_data_{tool}_{configuration}.h5",
        metrics ="data/solution_metrics_{tool}_{configuration}.json",
    conda:
        "environment_simulation.yml",
    shell:
        """
        python3 {input.script} --input_parameter_file {input.parameters} --input_mesh_file {input.mesh} --output_solution_file_hdf5 {output.hdf5} --output_metrics_file {output.metrics}
        """

rule summary:
    input:
        parameters = expand("{param}", param=[configuration_to_parameter_file[c] for c in configurations.values()]),
        mesh = expand("data/mesh_{configuration}.msh", configuration=configurations.values()),
        metrics = lambda wildcards: expand("data/solution_metrics_{tool}_{configuration}.json", tool=[wildcards.tool], configuration=configurations.values()),
        solution_field_data = lambda wildcards: expand("data/solution_field_data_{tool}_{configuration}.h5", tool=[wildcards.tool], configuration=configurations.values()),
    output:
        summary_json = "data/summary_{tool}.json",
        summary_h5 = "data/summary_{tool}.h5",
    conda: "environment_postprocessing.yml",
    run:
        import json
        import h5py
        from pathlib import Path

        all_summaries = []
        print("configurations:", configurations.values())
        with h5py.File(output.summary_h5, "w") as h5f:
            for idx, config in enumerate(configurations.values()):
                print(f"loop over config: {config}")
                mesh_path = input.mesh[idx]
                mesh_dataset_name = Path(mesh_path).name
                with open(mesh_path, "rb") as mesh_file:
                    mesh_data = mesh_file.read()
                    mesh_ds_name = f"{config}/mesh"
                    if mesh_ds_name in h5f:
                        raise RuntimeError(f"Dataset already exists: {mesh_ds_name}")
                    h5f.create_dataset(mesh_ds_name, data=mesh_data)
                with h5py.File(input.solution_field_data[idx], "r") as src_h5f:
                    for name, dataset in src_h5f.items():
                        ds_name = f"{config}/{name}"
                        if ds_name in h5f:
                            raise RuntimeError(f"Dataset already exists: {ds_name}")
                        h5f.create_dataset(ds_name, data=dataset[()])
        for idx, config in enumerate(configurations.values()):
            summary = {}
            summary["benchmark"] = "linear-elastic-plate-with-hole"
            with open(input.parameters[idx], "r") as param_file:
                summary["parameters"] = json.load(param_file)
            summary["mesh"] = f"{config}/mesh"
            with open(input.metrics[idx], "r") as metrics_file:
                summary["metrics"] = json.load(metrics_file)
            summary["configuration"] = config
            all_summaries.append(summary)

        with open(output.summary_json, "w") as f:
            json.dump(all_summaries, f, indent=4)